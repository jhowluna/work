{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2F-hvs7WrjLy"
   },
   "source": [
    "# Testando o modelo do Detector de Emoções com Múltiplas Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz8aXNC5tOyC"
   },
   "source": [
    "## Etapa 1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bx7mqEk_snHV"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xlqATqJss_Wu",
    "outputId": "ddf64e99-7e21-46ec-b7d8-194edb81c663"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zyUs6DCXtOHA",
    "outputId": "80cfb3a3-2dac-4296-dbad-9d238c726b5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.3.1'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ph2GPO8tXGg"
   },
   "source": [
    "## Etapa 2 - Conectando com o Drive e acessando os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "yS0NqXIOzRcf",
    "outputId": "178cc527-8727-4609-d35b-9080647746a7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-19e6feed25e4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolab\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdrive\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdrive\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmount\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'/content/gdrive'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NGJY3i8Bzvsm",
    "outputId": "f2f17f9e-c5d1-4faa-d7ea-1f1609051fb9"
   },
   "outputs": [],
   "source": [
    "path = \"/content/gdrive/My Drive/Material.zip\"\n",
    "zip_object = zipfile.ZipFile(file = path, mode = \"r\")\n",
    "zip_object.extractall('./')\n",
    "zip_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V4LRao9X0T4e",
    "outputId": "9996f346-33df-4d16-c24f-5c8cacc74361"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2_imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-e9ff999837b5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mimagem\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Material/testes/teste03.jpg'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mcv2_imshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimagem\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cv2_imshow' is not defined"
     ]
    }
   ],
   "source": [
    "imagem = cv2.imread('Material/testes/teste03.jpg')\n",
    "cv2_imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2hm0WkrG8Btu",
    "outputId": "0e787837-f752-4dbf-b9c4-81bf919d52b4"
   },
   "outputs": [],
   "source": [
    "imagem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBfMPIqRvETM"
   },
   "source": [
    "## Testando o Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQxAjBLIyIIe"
   },
   "source": [
    "### Carregamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N86gbyYh5pd4"
   },
   "outputs": [],
   "source": [
    "cascade_faces = \"Material/haarcascade_frontalface_default.xml\"\n",
    "caminho_modelo = \"Material/modelo_01_expressoes.h5\"\n",
    "face_detection = cv2.CascadeClassifier(cascade_faces)\n",
    "classificador_emocoes = load_model(caminho_modelo, compile = False)\n",
    "expressoes = [\"Raiva\", \"Nojo\", \"Medo\", \"Feliz\", \"Triste\", \"Surpreso\", \"Neutro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNBTnZnQyx60"
   },
   "source": [
    "### Detecção de faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpjOfRqo7Ub4"
   },
   "outputs": [],
   "source": [
    "faces = face_detection.detectMultiScale(imagem, scaleFactor = 1.2,\n",
    "                                        minNeighbors = 5, minSize = (20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "RZUUatiU73qE",
    "outputId": "629334a1-63b1-4c60-eb4c-1bdc3b3a76e6"
   },
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TCjeLsUP8a9Z",
    "outputId": "f9999763-936a-4373-97ad-180df0b40a95"
   },
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XDVrjp2r8do7",
    "outputId": "620d46eb-017c-416c-aa54-68111636d2b5"
   },
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeISYAw_07zB"
   },
   "source": [
    "### Processamento para cada rosto detectado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZSkIbmSq9FtF",
    "outputId": "a5490711-a6e2-4b2c-fc60-418f657250e7"
   },
   "outputs": [],
   "source": [
    "cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "cv2_imshow(cinza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GhypHZTe9e56",
    "outputId": "97da7edb-cafe-411e-c305-16498fe282fa"
   },
   "outputs": [],
   "source": [
    "cinza.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq2hCp6gBGsU"
   },
   "source": [
    "Com o *for* são realizados as etapas para cada face detectada:\n",
    "* Extração do ROI (region of interest)  \n",
    "* Redimensionamento\n",
    "* Normalização\n",
    "* Previsões e resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2oCVhujF9kjD",
    "outputId": "e5179776-d6ae-48d4-db6a-59cf07bfc0b4"
   },
   "outputs": [],
   "source": [
    "original = imagem.copy()\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "  # Extração do ROI (region of interest)  \n",
    "  roi = cinza[y:y + h, x:x + w] # utilizamos as coordenadas (onde inicia a face) e a largura e altura para extrair a região de interesse\n",
    "\n",
    "  # Redimensiona imagem\n",
    "  roi = cv2.resize(roi, (48, 48))\n",
    "\n",
    "  cv2_imshow(roi)\n",
    "  \n",
    "  # Normalização\n",
    "  roi = roi.astype(\"float\") / 255\n",
    "  roi = img_to_array(roi)\n",
    "  roi = np.expand_dims(roi, axis = 0)\n",
    "\n",
    "  # Previsões\n",
    "  preds = classificador_emocoes.predict(roi)[0]\n",
    "  print(preds)\n",
    "\n",
    "  # Emoção detectada\n",
    "  emotion_probability = np.max(preds)\n",
    "  print(emotion_probability)\n",
    "\n",
    "  print(preds.argmax())\n",
    "  label = expressoes[preds.argmax()]\n",
    "\n",
    "\n",
    "  # Mostra resultado na tela para o rosto\n",
    "  cv2.putText(original, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65,\n",
    "            (0, 0, 255), 2, cv2.LINE_AA)\n",
    "  cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4AUsGub2vWD"
   },
   "source": [
    "### Exibe resultado final\n",
    "\n",
    "> Perceba que no resultado final algumas faces não foram detectadas pelo haarscascade. Para solucionar, você pode fazer ajustes nos parâmetros no método `detectMultiScale`\n",
    "\n",
    "> Na última imagem, o algoritmo detectou duas faces. Também poderiam ser feito ajustes nos parâmetros ou então utilizar o Dlib para a detecção de faces, que é uma biblioteca com resultados melhores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j1n1HnNTCEGi",
    "outputId": "2b445720-3760-48b2-f371-e19dc03af019"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(original)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Testes com o Detector de Emoção - Múltiplas Faces",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-f852dfc3",
   "language": "python",
   "display_name": "PyCharm (Reconhecimento Emocoes TF Python)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}